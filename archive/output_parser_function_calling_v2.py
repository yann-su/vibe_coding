"""
æ™ºè°± API Function Calling æ”¹è¿›ç‰ˆ
é€šè¿‡ prompt æŒ‡å¯¼ + function calling çº¦æŸï¼Œç»•è¿‡ GLM-4.7 çš„ bug
"""

import requests
import json
from typing import List, Optional, Type
from pydantic import BaseModel, Field


def call_glm_with_function_v2(
    prompt: str,
    pydantic_model: Type[BaseModel],
    api_key: str = "9c575fbc0d714aa5a2ed2b1fec1359ec.Ve1Wz7QLlCHCsTiG"
) -> Optional[BaseModel]:
    """
    æ”¹è¿›ç‰ˆï¼šä½¿ç”¨ prompt æ˜ç¡®æŒ‡å¯¼æ¨¡å‹ç”Ÿæˆå‚æ•°ï¼ŒåŒæ—¶ç”¨ function calling çº¦æŸæ ¼å¼
    """
    schema = pydantic_model.model_json_schema()

    # ä» schema ä¸­æå–å­—æ®µä¿¡æ¯
    properties = schema.get('properties', {})
    required = schema.get('required', [])

    # æ„å»ºå­—æ®µæè¿°
    fields_desc = []
    for field_name, field_info in properties.items():
        desc = field_info.get('description', field_name)
        field_type = field_info.get('type', 'any')
        fields_desc.append(f"  - {field_name} ({field_type}): {desc}")

    fields_text = '\n'.join(fields_desc)

    tool_name = f"extract_{pydantic_model.__name__.lower()}"

    # æ„å»ºå·¥å…·å®šä¹‰
    tools = [{
        "type": "function",
        "function": {
            "name": tool_name,
            "description": f"æå–{pydantic_model.__name__}ä¿¡æ¯ã€‚ä½¿ç”¨æ­¤å‡½æ•°æ—¶ï¼Œå¿…é¡»åœ¨argumentsä¸­åŒ…å«ä»¥ä¸‹æ‰€æœ‰å­—æ®µçš„å®Œæ•´å€¼ï¼š\n{fields_text}",
            "parameters": schema
        }
    }]

    # å…³é”®æ”¹è¿›ï¼šåœ¨ prompt ä¸­æ˜ç¡®è¦æ±‚æ¨¡å‹ç”Ÿæˆå…·ä½“å‚æ•°å€¼
    enhanced_prompt = f"""{prompt}

ã€é‡è¦ã€‘ä½ éœ€è¦ä½¿ç”¨ {tool_name} å‡½æ•°æ¥è¿”å›ç»“æœã€‚
è¯·åœ¨å‡½æ•°è°ƒç”¨å‚æ•°ä¸­å¡«å†™ä»¥ä¸‹å­—æ®µçš„å…·ä½“å€¼ï¼š
{fields_text}

è¯·ç¡®ä¿å¡«å†™æ‰€æœ‰å¿…å¡«å­—æ®µï¼Œä¸è¦ç•™ç©ºã€‚"""

    url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "glm-4.7",
        "messages": [{"role": "user", "content": enhanced_prompt}],
        "tools": tools,
        "tool_choice": {
            "type": "function",
            "function": {"name": tool_name}
        }
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()

        print(f"ğŸ“¡ API å“åº”:")
        message = result["choices"][0]["message"]

        # æå–å‚æ•°
        if "tool_calls" in message and message["tool_calls"]:
            tool_call = message["tool_calls"][0]
            arguments = tool_call["function"]["arguments"]

            if isinstance(arguments, str):
                arguments = json.loads(arguments)

            print(f"\nğŸ“ æå–çš„å‚æ•°:")
            print(json.dumps(arguments, indent=2, ensure_ascii=False))

            # éªŒè¯å‚æ•°å®Œæ•´æ€§
            missing_fields = [f for f in required if f not in arguments or not arguments[f]]
            if missing_fields:
                print(f"\nâš ï¸ ç¼ºå°‘å­—æ®µ: {missing_fields}")
                # å°è¯•ç”¨ content è¡¥å……
                if message.get("content"):
                    print(f"\nğŸ’¡ å°è¯•ä» content è§£æ...")
                    arguments = extract_from_content(message["content"], properties, arguments)
                    missing_fields = [f for f in required if f not in arguments or not arguments[f]]
                    if not missing_fields:
                        print("âœ… è¡¥å……æˆåŠŸ!")

            if not missing_fields:
                return pydantic_model(**arguments)
            else:
                print(f"âŒ ä»ç¼ºå°‘å­—æ®µ: {missing_fields}")
                return None
        else:
            # æ²¡æœ‰ tool_callsï¼Œå°è¯•ä» content è§£æ
            print(f"\nâš ï¸ æ²¡æœ‰ function callingï¼Œå°è¯•è§£æ content:")
            content = message.get("content", "")
            print(content[:500])
            return None

    except Exception as e:
        print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_from_content(content: str, properties: dict, existing: dict) -> dict:
    """å°è¯•ä» content ä¸­æå–å­—æ®µå€¼"""
    result = existing.copy()

    # ç®€å•å¯å‘å¼ï¼šä» reasoning_content æˆ– content ä¸­æå–
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è§£æé€»è¾‘

    return result


# ========== æ–¹æ³• 2: æµå¼ç”Ÿæˆå‚æ•° ==========
def call_glm_streaming_params(
    prompt: str,
    pydantic_model: Type[BaseModel],
    api_key: str = "9c575fbc0d714aa5a2ed2b1fec1359ec.Ve1Wz7QLlCHCsTiG"
) -> Optional[BaseModel]:
    """
    æ–¹æ³• 2: ä¸ä½¿ç”¨ tool_choice å¼ºåˆ¶ï¼Œè®©æ¨¡å‹è‡ªå·±é€‰æ‹©
    æœ‰æ—¶æ¨¡å‹åœ¨è‡ªç”±é€‰æ‹©æ—¶è¡¨ç°æ›´å¥½
    """
    schema = pydantic_model.model_json_schema()
    tool_name = f"extract_{pydantic_model.__name__.lower()}"

    tools = [{
        "type": "function",
        "function": {
            "name": tool_name,
            "description": f"æå–{pydantic_model.__name__}ä¿¡æ¯",
            "parameters": schema
        }
    }]

    url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "glm-4.7",
        "messages": [{"role": "user", "content": prompt}],
        "tools": tools,
        # ä¸æŒ‡å®š tool_choiceï¼Œè®©æ¨¡å‹è‡ªå·±å†³å®š
    }

    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()

        message = result["choices"][0]["message"]

        print(f"ğŸ¯ Finish reason: {result['choices'][0].get('finish_reason')}")

        if "tool_calls" in message and message["tool_calls"]:
            tool_call = message["tool_calls"][0]
            arguments = tool_call["function"]["arguments"]

            if isinstance(arguments, str):
                arguments = json.loads(arguments)

            print(f"\nâœ… æˆåŠŸä½¿ç”¨ function calling!")
            print(f"ğŸ“ å‚æ•°: {json.dumps(arguments, indent=2, ensure_ascii=False)}")

            return pydantic_model(**arguments)
        else:
            print(f"\nâš ï¸ æ¨¡å‹é€‰æ‹©ä¸ä½¿ç”¨ function calling")
            print(f"Content: {message.get('content', 'æ— ')[:200]}")
            return None

    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return None


# ========== æ–¹æ³• 3: åˆ†ä¸¤æ­¥èµ° ==========
def call_glm_two_step(
    prompt: str,
    pydantic_model: Type[BaseModel],
    api_key: str = "9c575fbc0d714aa5a2ed2b1fec1359ec.Ve1Wz7QLlCHCsTiG"
) -> Optional[BaseModel]:
    """
    æ–¹æ³• 3: ç¬¬ä¸€æ­¥è®©æ¨¡å‹æ€è€ƒï¼Œç¬¬äºŒæ­¥å¼ºåˆ¶æ ¼å¼åŒ–
    """
    schema = pydantic_model.model_json_schema()

    # ç¬¬ä¸€æ­¥ï¼šè®©æ¨¡å‹ç”Ÿæˆå†…å®¹ï¼ˆæ™®é€šè°ƒç”¨ï¼‰
    url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    # æ„å»ºå­—æ®µæè¿°
    fields = '\n'.join([f"- {k}: {v.get('description', k)}"
                       for k, v in schema['properties'].items()])

    step1_prompt = f"""{prompt}

è¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
{fields}

è¯·ä»¥çº¯æ–‡æœ¬å½¢å¼åˆ—å‡ºè¿™äº›ä¿¡æ¯ã€‚"""

    data1 = {
        "model": "glm-4.7",
        "messages": [{"role": "user", "content": step1_prompt}]
    }

    try:
        response1 = requests.post(url, headers=headers, json=data1, timeout=30)
        response1.raise_for_status()
        content = response1.json()["choices"][0]["message"]["content"]

        print(f"ğŸ“ ç¬¬ä¸€æ­¥ç”Ÿæˆå†…å®¹:\n{content}\n")

        # ç¬¬äºŒæ­¥ï¼šç”¨ function calling æ ¼å¼åŒ–
        tool_name = f"format_{pydantic_model.__name__.lower()}"
        tools = [{
            "type": "function",
            "function": {
                "name": tool_name,
                "description": "å°†æ–‡æœ¬ä¿¡æ¯æ ¼å¼åŒ–ä¸ºç»“æ„åŒ–æ•°æ®",
                "parameters": schema
            }
        }]

        step2_prompt = f"""å°†ä»¥ä¸‹ä¿¡æ¯æ ¼å¼åŒ–ä¸º JSONï¼š
{content}

è¯·ä½¿ç”¨ {tool_name} å‡½æ•°è¿”å›æ ¼å¼åŒ–åçš„æ•°æ®ã€‚"""

        data2 = {
            "model": "glm-4.7",
            "messages": [{"role": "user", "content": step2_prompt}],
            "tools": tools,
            "tool_choice": {
                "type": "function",
                "function": {"name": tool_name}
            }
        }

        response2 = requests.post(url, headers=headers, json=data2, timeout=30)
        response2.raise_for_status()
        result = response2.json()

        message = result["choices"][0]["message"]
        if "tool_calls" in message and message["tool_calls"]:
            arguments = message["tool_calls"][0]["function"]["arguments"]
            if isinstance(arguments, str):
                arguments = json.loads(arguments)

            print(f"âœ… ç¬¬äºŒæ­¥æ ¼å¼åŒ–æˆåŠŸ!")
            print(f"ğŸ“ ç»“æœ: {json.dumps(arguments, indent=2, ensure_ascii=False)}")

            return pydantic_model(**arguments)
        else:
            print(f"âŒ ç¬¬äºŒæ­¥å¤±è´¥")
            return None

    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return None


# ========== æµ‹è¯• ==========
def demo_all_methods():
    """å¯¹æ¯”ä¸‰ç§æ–¹æ³•"""

    class Movie(BaseModel):
        name: str = Field(description="ç”µå½±åç§°")
        year: int = Field(description="ä¸Šæ˜ å¹´ä»½")
        director: str = Field(description="å¯¼æ¼”")
        rating: float = Field(description="è¯„åˆ† 0-10")
        genres: List[str] = Field(description="ç”µå½±ç±»å‹åˆ—è¡¨")

    prompt = "æ¨èä¸€éƒ¨2023å¹´çš„é«˜åˆ†ç§‘å¹»ç”µå½±"

    print("=" * 60)
    print("æ–¹æ³• 1: Prompt æŒ‡å¯¼ + å¼ºåˆ¶ tool_choice")
    print("=" * 60)
    result1 = call_glm_with_function_v2(prompt, Movie)
    if result1:
        print(f"\nâœ… æˆåŠŸ: {result1.name} ({result1.year})")

    print("\n" + "=" * 60)
    print("æ–¹æ³• 2: è®©æ¨¡å‹è‡ªä¸»é€‰æ‹©æ˜¯å¦ä½¿ç”¨ tool")
    print("=" * 60)
    result2 = call_glm_streaming_params(prompt, Movie)
    if result2:
        print(f"\nâœ… æˆåŠŸ: {result2.name} ({result2.year})")

    print("\n" + "=" * 60)
    print("æ–¹æ³• 3: ä¸¤æ­¥èµ°ï¼ˆç”Ÿæˆ + æ ¼å¼åŒ–ï¼‰")
    print("=" * 60)
    result3 = call_glm_two_step(prompt, Movie)
    if result3:
        print(f"\nâœ… æˆåŠŸ: {result3.name} ({result3.year})")


if __name__ == "__main__":
    print("ğŸ”§ æ™ºè°± API Function Calling æ”¹è¿›ç‰ˆ")
    print("æµ‹è¯•ä¸åŒæ–¹æ³•ç»•è¿‡ GLM-4.7 çš„ function calling bug\n")

    demo_all_methods()
